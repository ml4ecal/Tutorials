{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "<style>\n",
    "hr { \n",
    "  display: block;\n",
    "  margin-top: 1em;\n",
    "  margin-bottom: 0.5em;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  border-style: inset;\n",
    "  border-width: 10px;\n",
    "} \n",
    "    \n",
    "ul {\n",
    "border: solid 1px green;\n",
    "width:800px;\n",
    "margin:0 auto;\n",
    "padding: 0;\n",
    "}\n",
    "li {\n",
    "display:inline;\n",
    "list-style-type:none;\n",
    "}\n",
    "div {\n",
    "border: solid 1px red;\n",
    "width:900px;\n",
    "height:50px;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<h1><center>IT-TOOLS FOR PHYSICIST 2.0</center></h1>\n",
    "<h3><center> Authors: Wahid Redjeb, Giacomo Boldrini</center></h3>\n",
    " <hr width = \"50%\">  \n",
    "<h2><center>Machine Learning</center></h2>\n",
    "<h3><center> Regression and Classification using Keras and Tensorflow</center></h3>\n",
    "\n",
    "\n",
    "<body >\n",
    "        In the last lectures we studied the meaning of <b>Machine Learning</b> and in particular we saw what an <b>Artificial Neural Network</b> is, how to implement it and how to exploit it.\n",
    "            In this lecture we will see how to build <b>models</b> which permit us to perform Linear Regression and Classifications.\n",
    "   </body>\n",
    "   \n",
    "The notebook divided in two sections:<br>\n",
    "    <ul>\n",
    "        <li><a href='#Keras'>Keras</a></li>     \n",
    "        <li><a href=#section2>Tensorflow</a></li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Keras</center></h1>\n",
    "<hr width = '1%'><br>\n",
    "<img src ='./images/keras-logo-2018-large-1200.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "     <i>Keras</i> is an open source library written in Python for Machine Learning purposes. In particular Keras is an high level <b>API</b> for neural networks (Application Programming Interface) which works on Tensorflow.\n",
    "        This library was developed focusing on the possibility to perform \"experiment\" in a fast way.</br>\n",
    "        <ul>\n",
    "            <li>Keras permits an easy and fast prototipation of the algorithms.</li>\n",
    "            <li>It supports both Convolutional NN and Recurrent NN, and moreover it permits them combination.</li>\n",
    "       <li>An important feature of Keras is that with it we don't have to worry on which computation tool you are working on, Keras is written in a such way that it can be compiled on CPU or GPU.</li>\n",
    "        </ul>\n",
    "    \n",
    "\n",
    "More info about Keras: <a href=\"https://keras.io/\"> KERAS </a>\n",
    "\n",
    "</body>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: h5py in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "<h1><center> Tensorflow</center></h1>\n",
    "<hr width = '50%'>\n",
    "<img src ='./images/logo-color-tensorflow.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and it is also used for machine learning applications such as neural network.\n",
    "It has a flexible architecture which allows an easy deplyment of computation across a variety of platform (CPUs,GPUs,TPUs), and from desktops to cluster off servers to mobile and edge devices.\n",
    "It was originally developed by researchers and engineers from the Google Brain team within Google's AI organization.\n",
    "More info about TF: <a href=\"https://www.tensorflow.org/\"> TensorFlow </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.16.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/wahid/.local/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.11.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.1.7)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.33.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.21.1)\n",
      "Requirement already satisfied: h5py in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (40.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/wahid/Programs/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Tensorflow version:\",(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When experimenting with TensorFlow interactively, it's convenient to use <code>tf.InteractiveSession()</code>. Invoking this statement within IPython (an interactive Python Shell) will make TensorFlow behave almost imperatively, allowing beginners to play with tensors much mor easily. You will learn about imperative versus declarative style in greater depth later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7f02194d96a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Initializing Constant Tensors </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros:0' shape=(2,) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(2) #it takes the shape of the tensor, [dim1,....,dimn]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that TF returns a reference to thedesired tensor rather than the value of the tensor itself. To force the value of the tensor ro be returned, we will use the method <code>eval()</code> of the tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type returned by the method eval() is:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros(2)\n",
    "eval = a.eval()\n",
    "print(\"The type returned by the method eval() is: \",(type(a.eval())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we'd like a tensor filled with some quantity besides 1/0? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5.],\n",
       "       [5., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.fill((2,2), value = 5.)\n",
    "tensor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a similar method, <code>constant()</code> which allows the construction of tensors that shouldn't change during the program execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_tensor = tf.constant(3., shape = (10,2))\n",
    "const_tensor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Samping Random Tensors </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28077507, -0.1377521 ],\n",
       "       [-0.6763296 ,  0.02458041]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Someone can pass as argument the seed in order to have the same sampling\n",
    "normal_tensor = tf.random_normal((2,2), mean = 0, stddev=1, seed = 42)\n",
    "normal_tensor.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that machine learning systems often make use of very large ten‐\n",
    "sors that often have tens of millions of parameters. When we sample tens of millions\n",
    "of random values from the Normal distribution, it becomes almost certain that some\n",
    "sampled values will be far from the mean. Such large samples can lead to numerical\n",
    "instability, so it’s common to sample using <code>tf.truncated_normal()</code> instead of <code>tf.ran\n",
    "dom_normal()</code>. This function behaves the same as <code>tf.random_normal()</code> in terms of\n",
    "API, but drops and resamples all values more than two standard deviations from the\n",
    "mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28077507, -0.1377521 , -0.6763296 ],\n",
       "       [ 0.02458041, -0.46845472, -0.00246632],\n",
       "       [-0.9745911 ,  0.6638492 ,  0.4368011 ],\n",
       "       [-0.7038976 ,  0.6426843 ,  1.4513893 ],\n",
       "       [ 1.8412819 , -0.15879929, -1.0607921 ],\n",
       "       [ 1.5984018 , -0.11424706,  1.4045748 ],\n",
       "       [-0.05878579, -0.42446467, -0.37023765],\n",
       "       [-0.5268839 , -0.31035113, -0.59968674],\n",
       "       [-0.01448264,  1.9438368 , -0.5893153 ],\n",
       "       [ 1.15643   ,  1.0532719 ,  0.52549994]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_trunc_tensor = tf.truncated_normal((10,3), mean = 0, stddev = 1, seed = 42)\n",
    "norm_trunc_tensor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4059453 , -0.59825754],\n",
       "       [-1.8191795 , -0.3599682 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampling a tensor with a uniformly random entries in a fixed interval\n",
    "uniform_tensor = tf.random_uniform((2,2), minval = -2, maxval = 2)\n",
    "uniform_tensor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6.],\n",
       "       [6., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding tensors together\n",
    "c = tf.ones((2,2)) #return float32\n",
    "d = tf.fill((2,2), value = 5.)\n",
    "sum_tensor = c + d\n",
    "sum_tensor.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention with the type of tensor you are building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1210 19:37:47.630657 139648977106752 deprecation.py:323] From <ipython-input-14-e9a8cfa2abb1>:4: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.ones():  Tensor(\"ones:0\", shape=(2, 2), dtype=float32)\n",
      "tf.fill() Tensor(\"Fill_2:0\", shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6., 6.],\n",
       "       [6., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"tf.ones(): \",(c))\n",
    "d = tf.fill((2,2), value = 5.)\n",
    "#or\n",
    "new_d = tf.to_float(d)\n",
    "print(\"tf.fill()\", (d))\n",
    "try_sum = c + d\n",
    "new_try_sum = c + new_d\n",
    "new_try_sum.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14., 14.],\n",
       "       [14., 14.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling a tensor\n",
    "\n",
    "c = tf.fill((2,2), value = 2.)\n",
    "d = tf.fill((2,2,), value = 7.)\n",
    "scale_tensor = c * d\n",
    "scale_tensor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Matrix operation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the identity matrix\n",
    "identity = tf.eye(4)\n",
    "identity.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal: [1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 3., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 4., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 5., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 6., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 7., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 8., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating general diagonal matrix\n",
    "\n",
    "diag = tf.range(1,10,1.) #Creates 1-D tensor\n",
    "print(\"Diagonal:\",(diag.eval()))\n",
    "\n",
    "d_tensor = tf.diag(diag)\n",
    "d_tensor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "Transposed Matrix:\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Transposing a matrix\n",
    "\n",
    "matrix = tf.ones((4,2))\n",
    "print(\"Matrix:\\n\",(matrix.eval()))\n",
    "\n",
    "transp_matrix = tf.matrix_transpose(matrix)\n",
    "print(\"Transposed Matrix:\\n\",(transp_matrix.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Matrix multiplication </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[5. 5. 5.]\n",
      " [5. 5. 5.]] \n",
      "b:\n",
      " [[6. 6.]\n",
      " [6. 6.]\n",
      " [6. 6.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[90., 90.],\n",
       "       [90., 90.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.fill((2,3), value = 5.)\n",
    "b = tf.fill((3,2), value = 6.)\n",
    "print(\"a:\\n {} \\nb:\\n {}\".format(a.eval(),b.eval()))\n",
    "\n",
    "c = tf.matmul(a,b)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Tensor shape manipulation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "a shape:\n",
      " (10,)\n",
      "b:\n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "b shape:\n",
      " (5, 2)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones(10)\n",
    "print(\"a:\\n\",(a.eval()))\n",
    "print(\"a shape:\\n\",(a.get_shape()))\n",
    "\n",
    "b = tf.reshape(a,(5,2))\n",
    "\n",
    "print(\"b:\\n\",(b.eval()))\n",
    "print(\"b shape:\\n\",(b.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we can turn the original rank-1 tensor into a rank-2 tensor and then into\n",
    "a rank-3 tensor with tf.reshape. While all necessary shape manipulations can be\n",
    "performed with <code>tf.reshape()</code>, sometimes it can be convenient to perform simpler\n",
    "shape manipulations using functions such as <code>tf.expand_dims</code> or <code>tf.squeeze</code>.\n",
    "tf.expand_dims adds an extra dimension to a tensor of size 1. It’s useful for increas‐\n",
    "ing the rank of a tensor by one (for example, when converting a rank-1 vector into a\n",
    "rank-2 row vector or column vector). <code>tf.squeeze</code>, on the other hand, removes all\n",
    "dimensions of size 1 from a tensor. It’s a useful way to convert a row or column vector\n",
    "into a flat vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: (2,)\n",
      "a: [1. 1.]\n",
      "b shape: (1, 2)\n",
      "b: [[1. 1.]]\n",
      "Do you notice the difference?\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones(2)\n",
    "print(\"a shape:\",(a.get_shape()))\n",
    "print(\"a:\",(a.eval()))\n",
    "b = tf.expand_dims(a,0) #Expand first dimension\n",
    "print(\"b shape:\",(b.get_shape()))\n",
    "print(\"b:\",(b.eval()))\n",
    "print(\"Do you notice the difference?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: (2,)\n",
      "a:\n",
      " [1. 1.]\n",
      "b shape: (2, 1)\n",
      "b:\n",
      " [[1.]\n",
      " [1.]]\n",
      "Do you notice the difference?\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones(2)\n",
    "print(\"a shape:\",(a.get_shape()))\n",
    "print(\"a:\\n\",(a.eval()))\n",
    "b = tf.expand_dims(a,1) #Expand first dimension\n",
    "print(\"b shape:\",(b.get_shape()))\n",
    "print(\"b:\\n\",(b.eval()))\n",
    "print(\"Do you notice the difference?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape: (2, 1)\n",
      "b:\n",
      " [[1.]\n",
      " [1.]]\n",
      "d shape: (2,)\n",
      "d:\n",
      " [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "d = tf.squeeze(b) #Expand first dimension\n",
    "print(\"b shape:\",(b.get_shape()))\n",
    "print(\"b:\\n\",(b.eval()))\n",
    "print(\"d shape:\",(d.get_shape()))\n",
    "print(\"d:\\n\",(d.eval()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Broadcasting </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[1. 1.]\n",
      " [1. 1.]]\n",
      "b:\n",
      " [0. 1.]\n",
      "a shape: (2, 2), b shape: (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [1., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones((2,2))\n",
    "print(\"a:\\n\",(a.eval()))\n",
    "\n",
    "b = tf.range(0,2,1, dtype = tf.float32)\n",
    "print(\"b:\\n\",(b.eval()))\n",
    "\n",
    "print(\"a shape: {}, b shape: {}\".format(a.get_shape(), b.get_shape()))\n",
    "\n",
    "#Tensorflow permits to add array with different shape (Broadcasting --> Numpy)\n",
    "\n",
    "c = a + b \n",
    "c.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen the vector b is added to every row of the matrix a.\n",
    "Notice: remember to define the tensor with the correct type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TensorFlow session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, a <code>tf.Session()</code> object stores the context under which a computation\n",
    "is performed. At the beginning of this chapter, we used <code>tf.InteractiveSession()</code> to\n",
    "set up an environment for all TensorFlow computations. This call created a hidden\n",
    "global context for all computations performed. We then used <code>tf.Tensor.eval()</code> to execute our declaratively specified computations. Underneath the hood, this call is\n",
    "evaluated in context of this hidden global tf.Session. It can be convenient (and\n",
    "often necessary) to use an explicit context for a computation instead of a hidden context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "a = tf.ones((2,2))\n",
    "b = tf.matmul(a,a)\n",
    "\n",
    "b.eval(session = sess )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor b is evaluated in the context of the session \"sess\". The same operation che be done using the method <code>run()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we used constant tensors. While we could combine and recombine these tensors in any way we chose, we could never change the value of tensors themselves (only create new tensors with new values).\n",
    "The style of programming so far has been <i>functional</i> and not <i>stateful</i>. While functional computations are very useful, machine learning often depens heavily on stateful computations. Learning algorithms are essentially rules for updating stored tensors to explain provided data. If it is not possible to update these stored tensors, it would be hard to learn. \n",
    "The <code>tf.Variable()</code> class provides a wrapper around tensors that allows for stateful computations. The variables objects serve as holders for tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable tensor:  <tf.Variable 'Variable:0' shape=(3, 3) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "var_tensor = tf.Variable(tf.ones((3,3)))\n",
    "\n",
    "print(\"Variable tensor: \",(var_tensor))\n",
    "\n",
    "#var_tensor.eval() Try to evaluate this tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation fails since variables have to be explicitly initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_tensor.eval(session = sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Assigning values to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 3., 3.],\n",
       "       [3., 3., 3.],\n",
       "       [3., 3., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(var_tensor.assign(tf.fill((3,3),value = 3.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we tried to assign a value to variable <b>var_tensor</b> of not of shape (3,3)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(var_tensor.assign(tf.fill((2,2),value = 3.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the variable is fixed upon initilization and must be preserved with updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
